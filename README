# Cargo projects scraper

# Introduction

A Scraper that uses Selenium chromedriver to crawl libraries.io, crates.io and GitHub to collect Rust project data and the corresponding maintainer and contributor data of these projects.

All data that this crawler collects is available [here](https://drive.google.com/drive/folders/1akkvWyAV_OLyFnJgYdv-_Fov5Z8m0pED).

# Installation

To use this code, do the following steps:

1. Clone this repository.
2. Create and activate a virtual environment.
3. Run pip install -r requirements.txt.

# How to use the scrapers

First read the [documentation](https://docs.google.com/document/d/1wJWbDbL90ChDO4d2GOycmVYS8Fla83_UmT8ajXI6gMc/edit) to learn about each scraper.

Simply run the relevant scraper according to your data requirements.

**Note: Scraper 2 uses input produced by Scraper 1. Scraper 4 uses input produced by Scraper 3.**

## On your local

## On a vm

Consult the [vm project documentation](https://docs.google.com/document/d/12sC38QYEJ41JbHfuTamA_smBirvdcKxnc708_Vl9qXo/edit).





